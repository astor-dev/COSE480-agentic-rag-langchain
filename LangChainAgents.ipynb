{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPUwOvgUyZiz"
      },
      "source": [
        "requiremenrs.txt\n",
        "\n",
        "langchain\n",
        "langchain-openai\n",
        "langchainhub # langchain python라이브러리로 프롬프트, 에이전트, 체인 관련 패키지 모음\n",
        "langserve[all]\n",
        "\n",
        "faiss-cpu  # Facebook에서 개발 및 배포한 밀집 벡터의 유사도 측정, 클러스터링에 효율적인 라이브러리\n",
        "tavily-python # 언어 모델에 중립적인 디자인으로, 모든 LLM과 통합이 가능하도록 설계된 검색 API\n",
        "beautifulsoup4  #파이썬에서 사용할 수 있는 웹데이터 크롤링 라이브러리\n",
        "wikipedia\n",
        "\n",
        "fastapi #  Python의 API를 빌드하기 위한 웹 프레임워크\n",
        "uvicorn # ASGI(Asynchronous Server Gateway Interface) 서버\n",
        "urllib3 # 파이썬에서 HTTP 요청을 보내고 받는 데 사용되는 강력하고 유연한 라이브러리\n",
        "\n",
        "python-dotenv\n",
        "pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMMJXo_JyjhQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG4jKxckH1_c"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXEvb3WyJMcA"
      },
      "source": [
        "Tavily Search 를 사용하기 위해서는 API KEY를 발급 받아 등록해야 함.\n",
        "\n",
        "[Tavily Search API 발급받기](https://app.tavily.com/sign-in)\n",
        "\n",
        "발급 받은 API KEY 를 다음과 같이 환경변수에 등록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIxxUDEZI6ZR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv() \n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "tavily_api_key = os.getenv(\"TAVILY_API_KEY\")\n",
        "\n",
        "# 디버깅을 위한 프로젝트명을 기입합니다.\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"AGENT TUTORIAL\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWR_5-ANKJt-"
      },
      "source": [
        "search.invoke 함수는 주어진 문자열에 대한 검색을 실행\n",
        "\n",
        "invoke() 함수에 검색하고 싶은 검색어를 넣어 검색을 수행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezbT1NHQKP12"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hKlxX7cJ8tP"
      },
      "outputs": [],
      "source": [
        "# TavilySearchResults 클래스를 langchain_community.tools.tavily_search 모듈에서 가져옵니다.\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# TavilySearchResults 클래스의 인스턴스를 생성합니다\n",
        "# k=5은 검색 결과를 5개까지 가져오겠다는 의미입니다\n",
        "search = TavilySearchResults(k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2KnGx9mSKQ8H"
      },
      "outputs": [],
      "source": [
        "# 검색 결과를 가져옵니다.\n",
        "search.invoke(\"판교 카카오 프렌즈샵 아지트점의 전화번호는 무엇인가요?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mHSqB3_Kvf3"
      },
      "source": [
        "#PDF 기반 문서 검색 도구: Retriever\n",
        "\n",
        "내부 데이터에 대해 조회를 수행할 retriever 생성.\n",
        "\n",
        "*   웹 기반 문서 로더, 문서 분할기, 벡터 저장소, 그리고 OpenAI 임베딩을 사용하여 문서 검색 시스템을 구축\n",
        "*   PDF 문서를 FAISS DB 에 저장하고 조회하는 retriever 를 생성\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnw_piOXK40_"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# PDF 파일 로드. 파일의 경로 입력\n",
        "loader = PyPDFLoader(\"/content/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
        "\n",
        "# 텍스트 분할기를 사용하여 문서를 분할합니다.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "# 문서를 로드하고 분할합니다.\n",
        "split_docs = loader.load_and_split(text_splitter)\n",
        "\n",
        "embedding_model = OpenAIEmbeddings()\n",
        "# VectorStore를 생성합니다.\n",
        "vector = FAISS.from_documents(split_docs, embedding_model)\n",
        "\n",
        "# Retriever를 생성합니다.\n",
        "retriever = vector.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pklmrBUMez_"
      },
      "source": [
        "retriever 객체의 get_relevant_documents 메소드를 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qhkeX8tMNT-"
      },
      "outputs": [],
      "source": [
        "# PDf 문서에서 Query 에 대한 관련성 높은 Chunk 를 가져옵니다.\n",
        "retriever.get_relevant_documents(\n",
        "    \"YouTube의 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 알려줘\"\n",
        ")[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6vRGZRVMupo"
      },
      "source": [
        "create_retriever_tool 함수는 langchain 라이브러리의 tools.retriever 모듈에서 가져온다. 이 함수는 특정 데이터를 검색하기 위한 도구를 생성하는 데 사용된다. langchain은 언어 모델과 관련된 다양한 기능을 제공하는 라이브러리로, 이 중 검색 도구 생성 기능은 데이터 검색 및 처리 작업을 용이하게 한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UD_fSoKMwYX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4excfbIjMiCZ"
      },
      "outputs": [],
      "source": [
        "# langchain 패키지의 tools 모듈에서 retriever 도구를 생성하는 함수를 가져옵니다.\n",
        "from langchain.tools.retriever import create_retriever_tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1KkwVBWMxL-"
      },
      "outputs": [],
      "source": [
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    name=\"pdf_search\",\n",
        "    description=\"2023년 12월 AI 관련 정보를 PDF 문서에서 검색합니다. '2023년 12월 AI 산업동향' 과 관련된 질문은 이 도구를 사용해야 합니다!\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRVXMqfzM6i3"
      },
      "source": [
        "# Agent 가 사용할 도구 목록 정의\n",
        "\n",
        "이제 두 가지를 모두 만들었으므로, Agent 가 사용할 도구 목록을 만들 수 있습니다.\n",
        "\n",
        "tools 리스트는 search와 retriever_tool을 포함합니다.\n",
        "\n",
        "이 리스트는 검색 및 정보 검색 도구를 저장하는 데 사용됩니다.\n",
        "\n",
        "각 요소는 특정 작업을 수행하는 데 필요한 기능을 제공합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2yOheWIM_lQ"
      },
      "outputs": [],
      "source": [
        "# tools 리스트에 search와 retriever_tool을 추가합니다.\n",
        "tools = [search, retriever_tool]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ez0vILVND5o"
      },
      "source": [
        "# 에이전트 생성\n",
        "\n",
        "이제 도구를 정의했으니 에이전트를 생성할 수 있습니다.\n",
        "\n",
        "OpenAI Functions 에이전트를 사용할 것입니다.\n",
        "\n",
        "먼저, 에이전트가 활용할 LLM을 정의합니다.\n",
        "\n",
        "ChatOpenAI 클래스는 langchain_openai 모듈에서 가져온 것으로, OpenAI의 언어 모델을 활용하여 대화형 AI를 구현할 수 있게 해줍니다.\n",
        "\n",
        "이 예제에서는 gpt-4-turbo-preview 모델을 사용하며, temperature 매개변수를 0으로 설정하여 예측의 변동성을 최소화합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNLsTBscNMVv"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# ChatOpenAI 클래스를 langchain_openai 모듈에서 가져옵니다.\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHTTQeuaNTzn"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "\n",
        "# hub에서 prompt를 가져옵니다 - 이 부분을 수정할 수 있습니다!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "# prompt 의 messages를 출력합니다.\n",
        "prompt.messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIOlNAWbNrQh"
      },
      "source": [
        " LLM, 프롬프트 및 도구로 에이전트를 초기화\n",
        "\n",
        "에이전트는 입력을 받아 어떤 Action 을 취할지 결정하는 역할을 수행하고 Action 들을 실행하는 것은 AgentExecutor(다음 단계)에 의해 수행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0YdzBcdNZ2Y"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_openai_functions_agent\n",
        "\n",
        "# OpenAI 함수 기반 에이전트를 생성합니다.\n",
        "# llm, tools, prompt를 인자로 사용합니다.\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X9NDlR4OKcI"
      },
      "source": [
        "에이전트(agent)를 AgentExecutor 내부의 도구들과 결합(이는 반복적으로 에이전트를 호출하고 도구들을 실행할 것임).\n",
        "\n",
        "이 코드는 langchain.agents 모듈에서 AgentExecutor 클래스를 가져와 인스턴스를 생성.\n",
        "\n",
        "생성 시, agent, tools 객체를 인자로 전달하고, verbose=True를 설정하여 상세한 로그 출력을 활성화.\n",
        "\n",
        "AgentExecutor는 주어진 에이전트와 도구들을 사용하여 작업을 실행하는 역할 수행."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeo2DPijOeqP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1vIKINiNghp"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "# AgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNNcBTkvOiv3"
      },
      "source": [
        "# 에이전트 실행하기\n",
        "\n",
        "agent_executor 객체의 invoke 메소드는 딕셔너리 형태의 인자를 받아 처리\n",
        "."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpwKhsuuOfdu"
      },
      "outputs": [],
      "source": [
        "# 'agent_executor' 객체의 'invoke' 메소드를 호출하여,\n",
        "# 'input' 키와 '안녕, 반가워' 값을 가진 딕셔너리를 인자로 전달합니다.\n",
        "response = agent_executor.invoke({\"input\": \"2024년 아시안컵 대한민국의 축구 경기 결과를 알려줘.\"})\n",
        "print(f'답변: {response[\"output\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTkbkYKrQ0j3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWDn12KkQ1s-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSpc6Mi3O_WG"
      },
      "outputs": [],
      "source": [
        "# 'agent_executor' 객체의 'invoke' 메소드를 호출하여, 'langsmith'가 테스팅에 어떻게 도움을 줄 수 있는지에 대한 질문을 입력으로 제공합니다.\n",
        "response = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"YouTube 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 PDF 문서에서 알려줘\"\n",
        "    }\n",
        ")\n",
        "print(f'답변: {response[\"output\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnuBp7uiPGlf"
      },
      "outputs": [],
      "source": [
        "# 검색 결과를 요청 후 질문에 대한 답변을 출력합니다.\n",
        "response = agent_executor.invoke(\n",
        "    {\"input\": \"판교 카카오 프렌즈샵 아지트점의 전화번호를 검색하여 결과를 알려주세요.\"}\n",
        ")\n",
        "print(f'답변: {response[\"output\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikzcw9pQQ2rY"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature=0,  # 창의성 0으로 설정\n",
        "                 model_name='gpt-4o-mini',  # 모델명\n",
        "                )\n",
        "\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm) #llm-math의 경우 나이 계산을 위해 사용\n",
        "agent = initialize_agent(tools,\n",
        "                         llm,\n",
        "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "                         description='위키피이아에서 정보를 검색하고 계산이 필요할 때 사용',\n",
        "                         verbose=True)\n",
        "\n",
        "\n",
        "agent.run(\"gpt-4o는 언제 출시되었어?\")\n",
        "\n",
        "#agent.run(\"에드 시런이 태어난 해는? 2024년도 현재 에드 시런은 몇 살?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D11RNrzXRZ9P"
      },
      "outputs": [],
      "source": [
        "# 필요한 모듈 import\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "########## 1. 도구를 정의합니다 ##########\n",
        "\n",
        "### 1-1. Search 도구 ###\n",
        "# TavilySearchResults 클래스의 인스턴스를 생성합니다\n",
        "# k=5은 검색 결과를 5개까지 가져오겠다는 의미입니다\n",
        "search = TavilySearchResults(k=5)\n",
        "\n",
        "### 1-2. PDF 문서 검색 도구 (Retriever) ###\n",
        "# PDF 파일 로드. 파일의 경로 입력\n",
        "loader = PyPDFLoader(\"SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
        "\n",
        "# 텍스트 분할기를 사용하여 문서를 분할합니다.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "# 문서를 로드하고 분할합니다.\n",
        "split_docs = loader.load_and_split(text_splitter)\n",
        "\n",
        "# VectorStore를 생성합니다.\n",
        "vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())\n",
        "\n",
        "# Retriever를 생성합니다.\n",
        "retriever = vector.as_retriever()\n",
        "\n",
        "# langchain 패키지의 tools 모듈에서 retriever 도구를 생성\n",
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,\n",
        "    name=\"pdf_search\",\n",
        "    # 도구에 대한 설명을 자세히 기입해야 합니다!!!\n",
        "    description=\"2023년 12월 AI 관련 정보를 PDF 문서에서 검색합니다. '2023년 12월 AI 산업동향' 과 관련된 질문은 이 도구를 사용해야 합니다!\",\n",
        ")\n",
        "\n",
        "### 1-3. tools 리스트에 도구 목록을 추가합니다 ###\n",
        "# tools 리스트에 search와 retriever_tool을 추가합니다.\n",
        "tools = [search, retriever_tool]\n",
        "\n",
        "########## 2. LLM 을 정의합니다 ##########\n",
        "# LLM 모델을 생성합니다.\n",
        "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\", temperature=0)\n",
        "\n",
        "########## 3. Prompt 를 정의합니다 ##########\n",
        "\n",
        "# hub에서 prompt를 가져옵니다 - 이 부분을 수정할 수 있습니다!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "print(prompt)\n",
        "########## 4. Agent 를 정의합니다 ##########\n",
        "\n",
        "# OpenAI 함수 기반 에이전트를 생성합니다.\n",
        "# llm, tools, prompt를 인자로 사용합니다.\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "\n",
        "########## 5. AgentExecutor 를 정의합니다 ##########\n",
        "\n",
        "# AgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "########## 6. 채팅 기록을 수행하는 메모리를 추가합니다. ##########\n",
        "\n",
        "# 채팅 메시지 기록을 관리하는 객체를 생성합니다.\n",
        "message_history = ChatMessageHistory()\n",
        "\n",
        "# 채팅 메시지 기록이 추가된 에이전트를 생성합니다.\n",
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    # 대부분의 실제 시나리오에서 세션 ID가 필요하기 때문에 이것이 필요합니다\n",
        "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
        "    lambda session_id: message_history,\n",
        "    # 프롬프트의 질문이 입력되는 key: \"input\"\n",
        "    input_messages_key=\"input\",\n",
        "    # 프롬프트의 메시지가 입력되는 key: \"chat_history\"\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "########## 7. 질의-응답 테스트를 수행합니다. ##########\n",
        "\n",
        "# 질의에 대한 답변을 출력합니다.\n",
        "response = agent_with_chat_history.invoke(\n",
        "    {\n",
        "        \"input\": \"YouTube 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 PDF 문서에서 알려줘\"\n",
        "    },\n",
        "    # 세션 ID를 설정합니다.\n",
        "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
        "    config={\"configurable\": {\"session_id\": \"MyTestSessionID\"}},\n",
        ")\n",
        "print(f\"답변: {response['output']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbFtuwavyXpn"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
